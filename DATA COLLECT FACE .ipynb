{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0d03d6f",
   "metadata": {},
   "source": [
    "# data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0cca94a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Your ID: T Hemanth Kumar\n",
      "Dataset Collection Done..................\n"
     ]
    }
   ],
   "source": [
    "# color images \n",
    "import cv2\n",
    "import os\n",
    "import face_recognition\n",
    "\n",
    "# Open the video capture\n",
    "video = cv2.VideoCapture(1)\n",
    "\n",
    "# Load the face detection classifier (not used in face_recognition)\n",
    "# facedetect = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Get user ID\n",
    "id = input(\"Enter Your ID: \")\n",
    "\n",
    "# Create a directory for the person (if it doesn't exist)\n",
    "person_dir = 'DATASET/' + str(id)\n",
    "os.makedirs(person_dir, exist_ok=True)\n",
    "\n",
    "count = 1\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    # Detect faces using face_recognition library\n",
    "    face_locations = face_recognition.face_locations(frame)\n",
    "\n",
    "    for (top, right, bottom, left) in face_locations:\n",
    "        count += 1\n",
    "        # Save the face region as an image\n",
    "        face_image_path = os.path.join(person_dir, f'{count}.jpg')\n",
    "        cv2.imwrite(face_image_path, frame[top:bottom, left:right])\n",
    "\n",
    "        # Draw a rectangle around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (50, 50, 255), 1)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    # Break the loop if enough images have been collected\n",
    "    if count > 50:\n",
    "        break\n",
    "\n",
    "    # Wait for a key press\n",
    "    k = cv2.waitKey(1)\n",
    "\n",
    "# Release the video capture and close all windows\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Dataset Collection Done..................\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e833eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08811946",
   "metadata": {},
   "source": [
    "# create a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74aaa493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facial Recognition Model Trained.\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "from sklearn import neighbors\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Function to train a k-nearest neighbors classifier\n",
    "def train_knn(train_dir, model_save_path=None, n_neighbors=None, knn_algo='ball_tree'):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # Loop through each person in the training set\n",
    "    for class_dir in os.listdir(train_dir):\n",
    "        if not os.path.isdir(os.path.join(train_dir, class_dir)):\n",
    "            continue\n",
    "\n",
    "        # Loop through each image for the current person\n",
    "        for img_name in os.listdir(os.path.join(train_dir, class_dir)):\n",
    "            img_path = os.path.join(train_dir, class_dir, img_name)\n",
    "            image = face_recognition.load_image_file(img_path)\n",
    "            faces_bboxes = face_recognition.face_locations(image)\n",
    "\n",
    "            # If only one face is detected, add it to the training set\n",
    "            if len(faces_bboxes) == 1:\n",
    "                X.append(face_recognition.face_encodings(image, known_face_locations=faces_bboxes)[0])\n",
    "                y.append(class_dir)\n",
    "\n",
    "    # Train the KNN classifier\n",
    "    knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights='distance')\n",
    "    knn_clf.fit(X, y)\n",
    "\n",
    "    # Save the trained KNN classifier to a file\n",
    "    if model_save_path is not None:\n",
    "        with open(model_save_path, 'wb') as f:\n",
    "            pickle.dump(knn_clf, f)\n",
    "\n",
    "    return knn_clf\n",
    "\n",
    "# Directory where the face images are saved\n",
    "dataset_dir = 'DATASET'\n",
    "\n",
    "# Train the KNN classifier using the collected face images\n",
    "classifier = train_knn(dataset_dir, model_save_path='trained_model.clf', n_neighbors=5)\n",
    "print(\"Facial Recognition Model Trained.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352beb79",
   "metadata": {},
   "source": [
    "# test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b93c00fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import pickle\n",
    "import datetime\n",
    "import os\n",
    "import csv\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "\n",
    "# Load the trained KNN classifier\n",
    "with open('trained_model.clf', 'rb') as f:\n",
    "    knn_clf = pickle.load(f)\n",
    "\n",
    "    \n",
    "# Dictionary to store verification images and their encodings\n",
    "verification_images = {\n",
    "    'INDIRA': r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\A Indira\\15.jpg\",\n",
    "    'ROHITH': r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\A Rohit\\4.jpg\",\n",
    "    'EKKA ABHI': r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\Abhishek ekka\\4.jpg\",\n",
    "    'ADITYA': r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\B ADITYA\\44.jpg\",\n",
    "    'ABHISHIEK': r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\G ABHISHEK\\42.jpg\",\n",
    "    'HARSHA VARDHAN ': r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\B Harsha Vardhan\\29.jpg\",\n",
    "    'JITENDRA': r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\B Jithendra\\45.jpg\",\n",
    "    'PAVAN KUMAR': r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\B Pavan Kumar\\30.jpg\",\n",
    "    'TAJASWARAO': r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\B Tejaswarrao\\41.jpg\",\n",
    "    'BHASKAR': r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\D BHASKAR\\21.jpg\",\n",
    "    'NIHARIKA': r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\D Niharika\\15.jpg\",\n",
    "    'PURUSHOTHAM': r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\D Purushotham\\44.jpg\",\n",
    "    'RAMPRASADRAO': r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\D Ramprasad rao\\18.jpg\",\n",
    "    'SASIKANTH': r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\D Sasi Kanth\\43.jpg\",\n",
    "    'SNEHITA': r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\G Snehitha\\41.jpg\",\n",
    "    'SRIYAREDDY': r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\G Sriya Reddy\\21.jpg\",\n",
    "    'NARENDRA': r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\I Narendra\\3.jpg\",\n",
    "    'MANIKANTA': r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\J Manikanta\\31.jpg\",\n",
    "    'JAYARAJU': r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\K Jayaraju\\41.jpg\",\n",
    "    'VENKATSAI': r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\K Venkata Sai Teja\\16.jpg\",\n",
    "    'LAVANYA' : r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\Konganpalli Lavanya\\17.jpg\",\n",
    "    'CHANDINI' : r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\L Chandini\\18.jpg\",\n",
    "    'POJITHA' : r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\L Poojitha\\20.jpg\",\n",
    "    'GURUMONOHAR' :r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\M Guru Manohar\\31.jpg\",\n",
    "    'HARINI' : r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\M Haarini Sree\\17.jpg\",\n",
    "    'NAVEEN' : r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\M Naveen\\20.jpg\",\n",
    "    'PREMSAI' : r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\M RAJA PREM SAI\\16.jpg\",\n",
    "    'SAITEJA' : r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\M Sai Teja\\18.jpg\",\n",
    "    'KISHORE' : r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\P Nanda Kishore\\44.jpg\",\n",
    "    'VINOD' : r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\P Vinod\\29.jpg\",\n",
    "    'POJA' : r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\Pooja Chandwani\\30.jpg\",\n",
    "    'DILLESARARAO' : r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\R Dhilleeswar rao\\4.jpg\",\n",
    "    'SAICHARAN' :  r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\R Sai Charan\\15.jpg\",\n",
    "    'RASOOL' : r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\S K M Rasool\\7.jpg\",\n",
    "    'MADHURI' : r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\S Madhuri\\18.jpg\",\n",
    "    'NITISH' : r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\S Madhuri\\18.jpg\",\n",
    "    'SAMEERA' : r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\S SAMEERA\\39.jpg\",\n",
    "    'SAIKIRAN' : r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\S.sai kiran\\4.jpg\",\n",
    "    'HEMANTH' : r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\T Hemanth Kumar\\8.jpg\",\n",
    "    'SAISANDESH' : r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\T Jai Sandesh\\6.jpg\",\n",
    "    'PRASANNA' : r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\T Prasanna\\42.jpg\",\n",
    "    'SATYANARANAYA' : r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\T Satyanarayana\\18.jpg\",\n",
    "    'VIVEKANANDHA' : r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\T Vivekananda\\31.jpg\",\n",
    "    'ROHAN' : r\"C:\\Users\\vijay\\ABHISHEK JR FACE ATTENDENCE PROJECT SEP\\DATASET\\Y ROHAN KUMAR(221801350001)\\6.jpg\"\n",
    "    \n",
    "    # Add more persons as needed\n",
    "}\n",
    "\n",
    "# Load verification images and their encodings\n",
    "verification_encodings = {}\n",
    "for person, image_path in verification_images.items():\n",
    "    verification_image = face_recognition.load_image_file(image_path)\n",
    "    # Ensure that at least one face is detected\n",
    "    face_encodings = face_recognition.face_encodings(verification_image)\n",
    "    if face_encodings:\n",
    "        verification_encodings[person] = face_encodings[0]\n",
    "    else:\n",
    "        print(f\"No face detected in {person}'s image: {image_path}\")\n",
    "\n",
    "# Open the video capture\n",
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "# CSV file to record recognition and verification events\n",
    "csv_file_path = 'recognition_log.csv'\n",
    "\n",
    "# Folder to save all recognized faces\n",
    "output_folder = 'recognized_faces'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# File to save recognized names\n",
    "recognized_names_file_path = 'recognized_names.txt'\n",
    "\n",
    "# Metrics variables\n",
    "start_time = None\n",
    "total_recognitions = 0\n",
    "average_recognition_time = 0.0\n",
    "confidence_threshold = 0.5  # Set the confidence threshold as needed\n",
    "\n",
    "# CSV columns\n",
    "csv_columns = ['Timestamp',   'Year',   'Month', 'Date', 'Hour', 'Minute', 'Second', 'Name']\n",
    "\n",
    "with open(csv_file_path, 'w', newline='') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=csv_columns)\n",
    "    writer.writeheader()\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    # Detect faces using face_recognition library\n",
    "    face_locations = face_recognition.face_locations(frame)\n",
    "\n",
    "    # Ensure that there are face encodings\n",
    "    if len(face_locations) > 0:\n",
    "        face_encodings = face_recognition.face_encodings(frame, known_face_locations=face_locations)\n",
    "\n",
    "        # Perform face verification\n",
    "        for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "            name = knn_clf.predict([face_encoding])[0]\n",
    "            (top, right, bottom, left) = face_location\n",
    "\n",
    "            # Perform face recognition with confidence\n",
    "            face_distances = face_recognition.face_distance(list(verification_encodings.values()), face_encoding)\n",
    "            min_distance = min(face_distances)\n",
    "            if min_distance < confidence_threshold:\n",
    "                recognized_name = list(verification_encodings.keys())[list(face_distances).index(min_distance)]\n",
    "            else:\n",
    "                recognized_name = \"Unknown\"\n",
    "\n",
    "            # Log recognition event\n",
    "            with open(csv_file_path, 'a', newline='') as csv_file:\n",
    "                timestamp = datetime.datetime.now()\n",
    "                writer = csv.DictWriter(csv_file, fieldnames=csv_columns)\n",
    "                writer.writerow({\n",
    "                    'Timestamp': timestamp.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                    'Year': timestamp.year,\n",
    "                    'Month': timestamp.month,\n",
    "                    'Date': timestamp.day,\n",
    "                    'Hour': timestamp.hour,\n",
    "                    'Minute': timestamp.minute,\n",
    "                    'Second': timestamp.second,\n",
    "                    'Name': recognized_name\n",
    "                })\n",
    "\n",
    "            # Display the name of the recognized person\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(frame, f\"{recognized_name}\", (left + 6, bottom - 6), font, 0.5, (255, 255, 0), 1)  # Yellow text\n",
    "\n",
    "            # Draw a rectangle around the face\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "            if recognized_name != \"Unknown\":\n",
    "                # Save the recognized face to the output folder\n",
    "                face_image = frame[top:bottom, left:right]\n",
    "                face_filename = os.path.join(output_folder,\n",
    "                                             f\"{recognized_name}_{timestamp.strftime('%Y%m%d%H%M%S')}.jpg\")\n",
    "                cv2.imwrite(face_filename, face_image)\n",
    "\n",
    "                # Save the recognized name to the text file\n",
    "                with open(recognized_names_file_path, 'a') as names_file:\n",
    "                    names_file.write(f\"{recognized_name}\\n\")\n",
    "\n",
    "                # Display pop-up message\n",
    "                root = tk.Tk()\n",
    "                root.withdraw()\n",
    "                messagebox.showinfo(\"Attendance Taken\", f\"Attendance taken for {recognized_name}\")\n",
    "\n",
    "                # Update metrics\n",
    "                total_recognitions += 1\n",
    "                if start_time is not None:\n",
    "                    elapsed_time = (datetime.datetime.now() - start_time).total_seconds()\n",
    "                    average_recognition_time = (\n",
    "                            average_recognition_time * (total_recognitions - 1) + elapsed_time) / total_recognitions\n",
    "\n",
    "            # Record start time for the next face\n",
    "            start_time = datetime.datetime.now()\n",
    "\n",
    "    # Display metrics on the frame\n",
    "    cv2.putText(frame, f\"Total Recognitions: {total_recognitions}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                (0, 255, 255), 2)  # Yellow text\n",
    "    cv2.putText(frame, f\"Average Recognition Time: {average_recognition_time:.2f} seconds\", (10, 60),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Face Recognition and Verification\", frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all windows\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba3477b",
   "metadata": {},
   "source": [
    "# stream lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e4b11e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 20:38:40.097 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file_path = 'recognition_log.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Streamlit app\n",
    "st.title('Face Recognition Log Viewer')\n",
    "\n",
    "# Display the dataframe\n",
    "st.write(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9aa8b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Usage: streamlit run [OPTIONS] TARGET [ARGS]...\n",
      "Try 'streamlit run --help' for help.\n",
      "\n",
      "Error: Invalid value: File does not exist: face.py\n"
     ]
    }
   ],
   "source": [
    "!streamlit run face.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5505803d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d29d505",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
